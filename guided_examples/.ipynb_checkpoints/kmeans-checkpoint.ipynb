{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Example\n",
    "\n",
    "Implement K-Means algorithm with TensorFlow, and apply it to classify\n",
    "handwritten digit images. This example is using the MNIST database of\n",
    "handwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "Note: This example requires TensorFlow v1.1.0 or over.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing print function from python3 to python2\n",
    "from __future__ import print_function\n",
    "\n",
    "#importing numpy\n",
    "import numpy as np\n",
    "#importing tensorflow\n",
    "import tensorflow as tf\n",
    "#the graph for k-means clustering\n",
    "from tensorflow.contrib.factorization import KMeans\n",
    "\n",
    "# Ignore all GPUs, tf random forest does not benefit from it.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "#ignore all the warnings and don't show them in the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#importing debug library\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorFlow session\n",
    "#creating a session object which creates an environment where we can execute Operations and evaluate Tensors\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugger\n",
    "\n",
    "### Uncomment the below line and execute the code to run the debugger.\n",
    "\n",
    "### Go to the link once you start execution    \t\t\thttp://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the below line to run the debugger\n",
    "sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"localhost:6064\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-cb9d765bac8a>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "#from tensorflow examples import the mnist dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#read the input data, perform one hot encoding on it\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "#load the entire mnist data\n",
    "full_data_x = mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_steps = 50 # Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "k = 25 # The number of clusters\n",
    "num_classes = 10 # The 10 digits\n",
    "num_features = 784 # Each image is 28x28 pixels\n",
    "\n",
    "# Input images\n",
    "#Inserting a placeholder for a tensor equal to size of data\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "# Labels (for assigning a label to a centroid and testing)\n",
    "#Inserting a placeholder for a tensor equal to size of data for labels\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "\n",
    "# K-Means Parameters\n",
    "#Initialize k means with k clusters and use the cosine distance metric\n",
    "kmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine',\n",
    "                use_mini_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\factorization\\python\\ops\\clustering_ops.py:744: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "# Build KMeans graph\n",
    "(all_scores, cluster_idx, scores, cluster_centers_initialized,init_op,train_op) = kmeans.training_graph()\n",
    "cluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\n",
    "avg_distance = tf.reduce_mean(scores)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init_vars = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "ename": "_Rendezvous",
     "evalue": "<_Rendezvous of RPC that terminated with (StatusCode.UNAVAILABLE, Connect Failed)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_Rendezvous\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e43ae5774582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#run the graph fragment to execute the operation (initialize variables) and evaluate each tensor using data from feed_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfull_data_x\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#run the graph fragment to execute the operation (initialize clusters) and evaluate each tensor using data from feed_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfull_data_x\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\grpc_wrapper.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata, callable_runner, callable_runner_args, callable_options)\u001b[0m\n\u001b[0;32m    221\u001b[0m       self._sent_graph_version = publish_traceback(\n\u001b[0;32m    222\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grpc_debug_server_urls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m           self._sent_graph_version)\n\u001b[0m\u001b[0;32m    224\u001b[0m     return super(TensorBoardDebugWrapperSession, self).run(\n\u001b[0;32m    225\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\grpc_wrapper.py\u001b[0m in \u001b[0;36mpublish_traceback\u001b[1;34m(debug_server_urls, graph, feed_dict, fetches, old_graph_version)\u001b[0m\n\u001b[0;32m     61\u001b[0m     source_remote.send_graph_tracebacks(\n\u001b[0;32m     62\u001b[0m         \u001b[0mdebug_server_urls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         send_source=True)\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\source_remote.py\u001b[0m in \u001b[0;36msend_graph_tracebacks\u001b[1;34m(destinations, run_key, origin_stack, graph, send_source)\u001b[0m\n\u001b[0;32m    207\u001b[0m   _send_call_tracebacks(\n\u001b[0;32m    208\u001b[0m       \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin_stack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_eager_execution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcall_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m       graph=graph, send_source=send_source)\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\source_remote.py\u001b[0m in \u001b[0;36m_send_call_tracebacks\u001b[1;34m(destinations, origin_stack, is_eager_execution, call_key, graph, send_source)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsecure_channel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mstub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdebug_service_pb2_grpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEventListenerStub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[0mstub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSendTracebacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msend_source\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m       for path, source_files in zip(\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, request, timeout, metadata, credentials)\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwith_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0m_Rendezvous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_Rendezvous\u001b[0m: <_Rendezvous of RPC that terminated with (StatusCode.UNAVAILABLE, Connect Failed)>"
     ]
    }
   ],
   "source": [
    "# Run the initializer\n",
    "#run the graph fragment to execute the operation (initialize variables) and evaluate each tensor using data from feed_dict\n",
    "sess.run(init_vars, feed_dict={X: full_data_x})\n",
    "#run the graph fragment to execute the operation (initialize clusters) and evaluate each tensor using data from feed_dict\n",
    "sess.run(init_op, feed_dict={X: full_data_x})\n",
    "\n",
    "# Training\n",
    "#Train the algorithm for the steps pre-decided above\n",
    "for i in range(1, num_steps + 1):\n",
    "    #run the graph fragment to execute the operation (training, calculating avg distance) \n",
    "    #and evaluate each tensor using data from feed_dict\n",
    "    _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n",
    "                         feed_dict={X: full_data_x})\n",
    "    #check if the step is the first one or a multiple of 10\n",
    "    if i % 10 == 0 or i == 1:\n",
    "        #Print the step number if the above condition is true\n",
    "        print(\"Step %i, Avg Distance: %f\" % (i, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a label to each centroid\n",
    "# Count total number of labels per centroid, using the label of each training\n",
    "# sample to their closest centroid (given by 'idx')\n",
    "#creating a numpy array of zeros with shape (k,num_classes)\n",
    "counts = np.zeros(shape=(k, num_classes))\n",
    "#run the loop idx length times\n",
    "for i in range(len(idx)):\n",
    "    #increment the count matrix with train label values\n",
    "    counts[idx[i]] += mnist.train.labels[i]\n",
    "# Assign the most frequent label to the centroid\n",
    "#find the index of the max value in each row of count matrix\n",
    "labels_map = [np.argmax(c) for c in counts]\n",
    "#convert the list created above to a tensor\n",
    "labels_map = tf.convert_to_tensor(labels_map)\n",
    "\n",
    "# Evaluation ops\n",
    "# Lookup: centroid_id -> label\n",
    "#lookup id of labels using the tensor\n",
    "cluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n",
    "# Compute accuracy\n",
    "#compare the predicted label to the true label\n",
    "correct_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\n",
    "#calculate the accuracy of the predictions\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Test Model\n",
    "#load the test data and its corresponding labels\n",
    "test_x, test_y = mnist.test.images, mnist.test.labels\n",
    "#run the graph fragment to execute the operation (prediction and accutacy calculation) \n",
    "#and evaluate each tensor using data from feed_dict, print the accuracy\n",
    "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
